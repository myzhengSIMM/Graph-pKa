{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Cluster import Butina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_mae(similarity_list,d_list):\n",
    "    data=pd.DataFrame({'similarity':similarity_list,'d':d_list})\n",
    "    print(np.mean(data[(data['similarity']>=0.8)]['d']))\n",
    "    print(np.mean(data[(data['similarity']>=0.7)&(data['similarity']<0.8)]['d']))\n",
    "    print(np.mean(data[(data['similarity']>=0.6)&(data['similarity']<0.7)]['d']))\n",
    "    print(np.mean(data[(data['similarity']>=0.5)&(data['similarity']<0.6)]['d']))\n",
    "    print(np.mean(data[(data['similarity']<0.5)]['d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles_list = []\n",
    "with open('./Dataset/acidic_train_0.70_smiles.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n','').split('./t')\n",
    "        train_smiles_list.append(line[0])\n",
    "\n",
    "train_ms = [Chem.MolFromSmiles(i) for i in train_smiles_list]\n",
    "train_fps_list = [AllChem.GetMorganFingerprintAsBitVect(x,2,1024) for x in train_ms]\n",
    "\n",
    "test_smiles_list = []\n",
    "with open('./Dataset/acidic_test_0.15_smiles.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n','').split('./t')\n",
    "        test_smiles_list.append(line[0])\n",
    "        \n",
    "test_ms = [Chem.MolFromSmiles(i) for i in test_smiles_list]\n",
    "test_fps_list = [AllChem.GetMorganFingerprintAsBitVect(x,2,1024) for x in test_ms]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_list = []\n",
    "for test_fps in test_fps_list:\n",
    "    sims = DataStructs.BulkTanimotoSimilarity(test_fps,train_fps_list)\n",
    "    similarity_list.append(max(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "461\n",
      "789\n",
      "1101\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.array(similarity_list) >= 0.8))\n",
    "print(np.sum(np.array(similarity_list) >= 0.7))\n",
    "print(np.sum(np.array(similarity_list) >= 0.6))\n",
    "print(np.sum(np.array(similarity_list) >= 0.5))\n",
    "print(np.sum(np.array(similarity_list) <0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from My_Pka_Model import Pka_basic_view,Pka_acidic_view\n",
    "import torch\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer, CanonicalBondFeaturizer\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(smiles,model_view):\n",
    "\n",
    "    node_featurizer = CanonicalAtomFeaturizer(atom_data_field='h')\n",
    "    edge_featurizer = CanonicalBondFeaturizer(bond_data_field='h')\n",
    "    bg = smiles_to_bigraph(smiles= smiles, \n",
    "                  node_featurizer=node_featurizer,\n",
    "                  edge_featurizer=edge_featurizer,canonical_atom_order= False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_view.eval()\n",
    "        molecule_pka,atom_pka = model_view(bg,bg.ndata['h'], bg.edata['h'])\n",
    "        \n",
    "    return molecule_pka,atom_pka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5631147899948855\n",
      "\n",
      "0.3468739285718049\n",
      "0.421746282833191\n",
      "0.49756405009756915\n",
      "0.6533634371805928\n",
      "0.8659592023114531\n",
      "\n",
      "0.5616683274900125\n",
      "\n",
      "0.34459193350302625\n",
      "0.4328775995524653\n",
      "0.49373412039179815\n",
      "0.6657965660028691\n",
      "0.8416085490159567\n",
      "\n",
      "0.5677474436867235\n",
      "\n",
      "0.35063853587647276\n",
      "0.4459005534789179\n",
      "0.5036307349512691\n",
      "0.6298260904165847\n",
      "0.8884118779775467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acid_pred = Pka_acidic_view(node_feat_size = 74,\n",
    "                            edge_feat_size = 12,\n",
    "                            output_size = 1,\n",
    "                            num_layers= 6,\n",
    "                            graph_feat_size=200,\n",
    "                            dropout=0.2)\n",
    "\n",
    "for i in range(1,4):\n",
    "    acid_pred.load_state_dict(torch.load('./Trained_model/acidic_ramdom_split_{}.pkl'.format(i),map_location='cuda:0'))\n",
    "\n",
    "    with open('./Dataset/acidic_test_0.15_smiles.txt') as f: #acidic_test_0.15_smiles.txt,SAMPL7_acidic_smiles.txt\n",
    "        pred = []\n",
    "        label = []\n",
    "        for line in f.readlines():\n",
    "            line = line.replace('\\n','').split('\\t')\n",
    "            molecule_pka,atom_pka = predict(line[0],acid_pred)\n",
    "            pred.append(molecule_pka)\n",
    "            label.append(float(line[1]))\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(pred,label):\n",
    "        d_list.append(abs(i-j))\n",
    "        \n",
    "    d2_list = []\n",
    "    for i,j in zip(pred,label):\n",
    "        d2_list.append(abs(i-j)**2)\n",
    "    \n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7180528008050802\n",
      "\n",
      "0.2925636257645035\n",
      "0.5314559909539021\n",
      "0.6039035226576092\n",
      "0.8214677816924999\n",
      "1.3127253640570389\n",
      "\n",
      "0.7225474531042596\n",
      "\n",
      "0.2904779811245781\n",
      "0.5218297765737259\n",
      "0.6041993417263777\n",
      "0.8278270227365687\n",
      "1.3380749508206842\n",
      "\n",
      "0.7129630746816762\n",
      "\n",
      "0.28396072313607823\n",
      "0.5231702231021754\n",
      "0.5879862893763008\n",
      "0.8096424021418882\n",
      "1.3356828839500807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/acidic_RF_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "        \n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365571816432178\n",
      "\n",
      "0.2289065585505873\n",
      "0.5215912022423534\n",
      "0.5506061217614353\n",
      "0.7298912962348587\n",
      "1.1329916503782635\n",
      "\n",
      "0.6578560298301941\n",
      "\n",
      "0.2543316479151251\n",
      "0.5313747752884959\n",
      "0.5598924835801904\n",
      "0.7353751621719299\n",
      "1.1937745476723425\n",
      "\n",
      "0.646156457563291\n",
      "\n",
      "0.2475425800530838\n",
      "0.5373854846925372\n",
      "0.5599361867366698\n",
      "0.7408925670275258\n",
      "1.1272672379861968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/acidic_XGBoost_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "        \n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6633813163238147\n",
      "\n",
      "0.2904769581790385\n",
      "0.49825574134144607\n",
      "0.5742133608636963\n",
      "0.7527205206347005\n",
      "1.1735100080308019\n",
      "\n",
      "0.6750120846808126\n",
      "\n",
      "0.29616887268942593\n",
      "0.5102106899632636\n",
      "0.5755421910338963\n",
      "0.7733287422357983\n",
      "1.1930959748772065\n",
      "\n",
      "0.6823699984682632\n",
      "\n",
      "0.30792844285700616\n",
      "0.5179559538044113\n",
      "0.5691390520488684\n",
      "0.7855477079184272\n",
      "1.2073905334549422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/acidic_MLP_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "\n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511511713058918\n",
      "\n",
      "0.27902913605640633\n",
      "0.5804748878750527\n",
      "0.6467557997482791\n",
      "0.8371697134500413\n",
      "1.3887335345461636\n",
      "\n",
      "0.7511515556112494\n",
      "\n",
      "0.27904592069104245\n",
      "0.5804438844940327\n",
      "0.6467633331841114\n",
      "0.8371641847188115\n",
      "1.3887403016063864\n",
      "\n",
      "0.751153291072199\n",
      "\n",
      "0.27903729753191514\n",
      "0.5804690965287022\n",
      "0.6467661664900652\n",
      "0.8371592385348362\n",
      "1.388740602668775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/acidic_SVR_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "        \n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "\n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_smiles_list = []\n",
    "with open('./Dataset/basic_train_0.70_smiles.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n','').split('./t')\n",
    "        train_smiles_list.append(line[0])\n",
    "\n",
    "train_ms = [Chem.MolFromSmiles(i) for i in train_smiles_list]\n",
    "train_fps_list = [AllChem.GetMorganFingerprintAsBitVect(x,2,1024) for x in train_ms]\n",
    "\n",
    "test_smiles_list = []\n",
    "with open('./Dataset/basic_val_0.15_smiles.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n','').split('./t')\n",
    "        test_smiles_list.append(line[0])\n",
    "        \n",
    "test_ms = [Chem.MolFromSmiles(i) for i in test_smiles_list]\n",
    "test_fps_list = [AllChem.GetMorganFingerprintAsBitVect(x,2,1024) for x in test_ms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_list = []\n",
    "for test_fps in test_fps_list:\n",
    "    sims = DataStructs.BulkTanimotoSimilarity(test_fps,train_fps_list)\n",
    "    similarity_list.append(max(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "471\n",
      "742\n",
      "1037\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.array(similarity_list) >= 0.8))\n",
    "print(np.sum(np.array(similarity_list) >= 0.7))\n",
    "print(np.sum(np.array(similarity_list) >= 0.6))\n",
    "print(np.sum(np.array(similarity_list) >= 0.5))\n",
    "print(np.sum(np.array(similarity_list) <0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from My_Pka_Model import Pka_basic_view,Pka_acidic_view\n",
    "import torch\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer, CanonicalBondFeaturizer\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(smiles,model_view):\n",
    "\n",
    "    node_featurizer = CanonicalAtomFeaturizer(atom_data_field='h')\n",
    "    edge_featurizer = CanonicalBondFeaturizer(bond_data_field='h')\n",
    "    bg = smiles_to_bigraph(smiles= smiles, \n",
    "                  node_featurizer=node_featurizer,\n",
    "                  edge_featurizer=edge_featurizer,canonical_atom_order= False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_view.eval()\n",
    "        molecule_pka,atom_pka = model_view(bg,bg.ndata['h'], bg.edata['h'])\n",
    "        \n",
    "    return molecule_pka,atom_pka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5454750868965873\n",
      "\n",
      "0.3413756870886677\n",
      "0.38223755558280537\n",
      "0.4781652496595265\n",
      "0.5824909285914984\n",
      "0.9656985101087405\n",
      "\n",
      "0.5462946555091295\n",
      "\n",
      "0.37510384202281555\n",
      "0.3955962041556156\n",
      "0.47374806626004845\n",
      "0.5684354313121832\n",
      "0.940713068920622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_pred = Pka_basic_view(node_feat_size = 74,\n",
    "                            edge_feat_size = 12,\n",
    "                            output_size = 1,\n",
    "                            num_layers= 6,\n",
    "                            graph_feat_size=200,\n",
    "                            dropout=0.2)\n",
    "\n",
    "for i in range(1,4):\n",
    "    base_pred.load_state_dict(torch.load('./Trained_model/basic_ramdom_split_{}.pkl'.format(i),map_location='cuda:0'))\n",
    "\n",
    "    with open('./Dataset/basic_val_0.15_smiles.txt') as f: #acidic_test_0.15_smiles.txt,SAMPL7_acidic_smiles.txt\n",
    "        pred = []\n",
    "        label = []\n",
    "        for line in f.readlines():\n",
    "            line = line.replace('\\n','').split('\\t')\n",
    "            molecule_pka,atom_pka = predict(line[0],base_pred)\n",
    "            pred.append(molecule_pka)\n",
    "            label.append(float(line[1]))\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(pred,label):\n",
    "        d_list.append(abs(i-j))\n",
    "\n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "\n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175995905942668\n",
      "\n",
      "0.3648043264353553\n",
      "0.5884399428280607\n",
      "0.7071024377133166\n",
      "0.7845758668946006\n",
      "1.1929246305719712\n",
      "\n",
      "0.7115287247270602\n",
      "\n",
      "0.37805896942815903\n",
      "0.5545882264480962\n",
      "0.6987047827039368\n",
      "0.7730574913339625\n",
      "1.1916573598209057\n",
      "\n",
      "0.7201391665863911\n",
      "\n",
      "0.37242512043314246\n",
      "0.5810276019053178\n",
      "0.7167324825426059\n",
      "0.7865225087767754\n",
      "1.1891604605414774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/basic_RF_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "        \n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "        \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6320396966763908\n",
      "\n",
      "0.3265713968781833\n",
      "0.4876220803615234\n",
      "0.6246500152119896\n",
      "0.6675377488891218\n",
      "1.0923111404920527\n",
      "\n",
      "0.6311499665421315\n",
      "\n",
      "0.32906815033260883\n",
      "0.5173611946089249\n",
      "0.5896891489887076\n",
      "0.698202326336469\n",
      "1.0648265057409518\n",
      "\n",
      "0.6325447643858002\n",
      "\n",
      "0.32128768916803835\n",
      "0.4929745458286402\n",
      "0.6175926243021327\n",
      "0.6775818058810489\n",
      "1.0936484644324118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/basic_XGBoost_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "\n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6257972381640062\n",
      "\n",
      "0.3662677419455886\n",
      "0.5532492578929056\n",
      "0.5848692686956114\n",
      "0.6392494052901186\n",
      "1.0382551121124661\n",
      "\n",
      "0.6239365242836834\n",
      "\n",
      "0.35659030543803666\n",
      "0.5319502503798988\n",
      "0.5732650269859813\n",
      "0.6628727042459646\n",
      "1.0410505353278028\n",
      "\n",
      "0.6322117721213165\n",
      "\n",
      "0.36503519564222353\n",
      "0.5465750777068118\n",
      "0.5887522903839536\n",
      "0.6553150775968267\n",
      "1.0553082792167203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/basic_MLP_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "\n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "    \n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670543761333243\n",
      "\n",
      "0.350451271443242\n",
      "0.5344189090047676\n",
      "0.5966529377171756\n",
      "0.7229394484955333\n",
      "1.1782391868625222\n",
      "\n",
      "0.6670470881924825\n",
      "\n",
      "0.35043664085851406\n",
      "0.5344048744460879\n",
      "0.5966390914817443\n",
      "0.7229415532558002\n",
      "1.1782422616184158\n",
      "\n",
      "0.6670512012801414\n",
      "\n",
      "0.35044368958329164\n",
      "0.5344171017581916\n",
      "0.5966536273379187\n",
      "0.7229389309342126\n",
      "1.1782331898624596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    with open(\"./Machine_learning_model/basic_SVR_{}.pickle\".format(i), 'rb') as fr:\n",
    "        model = pickle.load(fr)\n",
    "\n",
    "    df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "    test_data_label = np.array(df_test)\n",
    "    X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    d_list = []\n",
    "    for i,j in zip(y_pred,y_test):\n",
    "        d_list.append(abs(i-j))\n",
    "\n",
    "    print(np.mean(d_list))\n",
    "    print('')\n",
    "\n",
    "    Hierarchical_mae(similarity_list,d_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
