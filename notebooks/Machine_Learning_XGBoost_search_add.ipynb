{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/basic_train_0.70_FP.csv',header = None)\n",
    "df_val = pd.read_csv('./Dataset/basic_val_0.15_FP.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5905, 9122)\n",
      "(1265, 9122)\n"
     ]
    }
   ],
   "source": [
    "train_data_label = np.array(df_train)\n",
    "print(train_data_label.shape)\n",
    "val_data_label = np.array(df_val)\n",
    "print(val_data_label.shape)\n",
    "X_train, X_val, y_train, y_val = train_data_label[:,1:],val_data_label[:,1:],train_data_label[:,0],val_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要参数 n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [50,100,300,500,1000,1500,2000]\n",
    "learning_rate_list = [0.05,0.1,0.2,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50\n",
      "learning_rate: 0.05\n",
      "1.1543099607156504\n",
      "1.501114135750497\n",
      "0.7722251402720883\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.1\n",
      "0.8730442095285845\n",
      "1.2382128023097345\n",
      "0.8450223973211866\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.2\n",
      "0.80235205507127\n",
      "1.162904546304546\n",
      "0.8633006355953192\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.5\n",
      "0.8211391317682433\n",
      "1.2053523979495337\n",
      "0.8531390169387472\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.05\n",
      "0.8716739923040269\n",
      "1.2289233523168392\n",
      "0.8473390529327212\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.1\n",
      "0.799563539804378\n",
      "1.1596287669413456\n",
      "0.8640696862623218\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.2\n",
      "0.735439606894115\n",
      "1.0892290673687393\n",
      "0.8800730459311678\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.5\n",
      "0.7841807544618352\n",
      "1.1780916767163456\n",
      "0.8597068282351428\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.05\n",
      "0.755334422762599\n",
      "1.108887080557294\n",
      "0.8757051868607376\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.1\n",
      "0.7152827654292515\n",
      "1.0703518368248686\n",
      "0.884193889389659\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.2\n",
      "0.6661865950208571\n",
      "1.0230682837832248\n",
      "0.8941995289963522\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.5\n",
      "0.7619960638070172\n",
      "1.169950826944265\n",
      "0.8616390370239431\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.05\n",
      "0.71581358161078\n",
      "1.0671053839806728\n",
      "0.8848953202818419\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.1\n",
      "0.685043957328844\n",
      "1.0439562654051113\n",
      "0.8898351699702113\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.2\n",
      "0.6478322189644575\n",
      "1.0088829869427471\n",
      "0.8971131299827457\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.5\n",
      "0.7507065200374154\n",
      "1.1623647875390597\n",
      "0.8634275033712442\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.05\n",
      "0.6689322761835603\n",
      "1.0263086804235126\n",
      "0.8935282572286929\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.1\n",
      "0.6531900953798325\n",
      "1.0214392028062413\n",
      "0.8945362031182846\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.2\n",
      "0.6321772119411472\n",
      "0.9995019417510882\n",
      "0.8990176105268864\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.5\n",
      "0.7466814711112276\n",
      "1.160972562037686\n",
      "0.8637544675815471\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.05\n",
      "0.6448422795121342\n",
      "1.0085044452246084\n",
      "0.8971903236046661\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.1\n",
      "0.6409234251373181\n",
      "1.0131033634578244\n",
      "0.8962505333157424\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.2\n",
      "0.6275225428140918\n",
      "0.9980846227166725\n",
      "0.8993037986368927\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.5\n",
      "0.7457027630625535\n",
      "1.1603906824547294\n",
      "0.8638910059098072\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.05\n",
      "0.6346306317307749\n",
      "1.0032241883865296\n",
      "0.898264072681919\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.1\n",
      "0.6344635550275335\n",
      "1.0108780291376134\n",
      "0.8967058149588236\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.2\n",
      "0.6252899667506188\n",
      "0.9975971572234064\n",
      "0.8994021348611855\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.5\n",
      "0.7457080707238557\n",
      "1.1604075972973156\n",
      "0.8638870377997141\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        model = XGBRegressor(n_estimators = n_estimators,learning_rate = learning_rate,random_state= 0,nthread = 20)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        print('n_estimators: '+ str(n_estimators))\n",
    "        print('learning_rate: '+ str(learning_rate))\n",
    "        print(mean_absolute_error(y_val, y_pred))\n",
    "        print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "        print(r2_score(y_val, y_pred))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据mae 选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = [0.9,0.8,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.9\n",
      "0.6495349159339565\n",
      "1.0384546392773413\n",
      "0.8909932427712208\n",
      "\n",
      "\n",
      "subsample: 0.8\n",
      "0.6498377150055695\n",
      "1.047669110506101\n",
      "0.8890501709917273\n",
      "\n",
      "\n",
      "subsample: 0.5\n",
      "0.6763921825196344\n",
      "1.0483136003011944\n",
      "0.8889136240116461\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subsample in subsample_list:\n",
    "    model = XGBRegressor(subsample = subsample, n_estimators = 2000,learning_rate = 0.2,random_state= 0,nthread = 24)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('subsample: '+ str(subsample))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators = 2000,learning_rate = 0.2, 加subsample，无下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = [0.9,0.8,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.9\n",
      "0.6177210754048409\n",
      "0.9943761370391143\n",
      "0.900050702561794\n",
      "\n",
      "\n",
      "subsample: 0.8\n",
      "0.615080996165443\n",
      "0.996544908876053\n",
      "0.8996142407400285\n",
      "\n",
      "\n",
      "subsample: 0.5\n",
      "0.6272524977317148\n",
      "0.997975723809748\n",
      "0.8993257709382142\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subsample in subsample_list:\n",
    "    model = XGBRegressor(subsample = subsample, n_estimators = 2000,learning_rate = 0.1,random_state= 0,nthread = 24)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('subsample: '+ str(subsample))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定为2000，0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acidic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/acidic_train_0.70_FP.csv',header = None)\n",
    "df_val = pd.read_csv('./Dataset/acidic_val_0.15_FP.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6337, 9122)\n",
      "(1358, 9122)\n"
     ]
    }
   ],
   "source": [
    "train_data_label = np.array(df_train)\n",
    "print(train_data_label.shape)\n",
    "val_data_label = np.array(df_val)\n",
    "print(val_data_label.shape)\n",
    "X_train, X_val, y_train, y_val = train_data_label[:,1:],val_data_label[:,1:],train_data_label[:,0],val_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [50,100,300,500,1000,1500,2000]\n",
    "learning_rate_list = [0.05,0.1,0.2,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50\n",
      "learning_rate: 0.05\n",
      "1.0904137811070265\n",
      "1.9048912287927595\n",
      "0.713262183263236\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.1\n",
      "0.9121991239374015\n",
      "1.5977661931845233\n",
      "0.7982697319750204\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.2\n",
      "0.820069237739408\n",
      "1.44496460479576\n",
      "0.835009466104389\n",
      "\n",
      "\n",
      "n_estimators: 50\n",
      "learning_rate: 0.5\n",
      "0.7948600475057918\n",
      "1.3964532435563313\n",
      "0.8459018559180228\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.05\n",
      "0.8945361032982457\n",
      "1.5293436414844923\n",
      "0.8151775284646277\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.1\n",
      "0.8080740856552112\n",
      "1.4536599519264757\n",
      "0.8330177680390524\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.2\n",
      "0.7582534058501852\n",
      "1.372395232674703\n",
      "0.8511657060613826\n",
      "\n",
      "\n",
      "n_estimators: 100\n",
      "learning_rate: 0.5\n",
      "0.7574370246836534\n",
      "1.3581233627238458\n",
      "0.8542451381302735\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.05\n",
      "0.76504455174266\n",
      "1.3402992602152346\n",
      "0.8580458263993238\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.1\n",
      "0.7288475477686479\n",
      "1.3747198747266927\n",
      "0.8506610708424397\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.2\n",
      "0.701984165232409\n",
      "1.303025738867027\n",
      "0.8658314893219238\n",
      "\n",
      "\n",
      "n_estimators: 300\n",
      "learning_rate: 0.5\n",
      "0.7381823212006725\n",
      "1.324610395037336\n",
      "0.8613496635413496\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.05\n",
      "0.727809972748405\n",
      "1.299809174594743\n",
      "0.8664930709969638\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.1\n",
      "0.6990504788734601\n",
      "1.3226030780462261\n",
      "0.8617695670806507\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.2\n",
      "0.6833251196019147\n",
      "1.2819516689268309\n",
      "0.8701362576011595\n",
      "\n",
      "\n",
      "n_estimators: 500\n",
      "learning_rate: 0.5\n",
      "0.7323241121629818\n",
      "1.3225214870978657\n",
      "0.8617866213343757\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.05\n",
      "0.6912131189358917\n",
      "1.254897361086433\n",
      "0.8755597078446743\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.1\n",
      "0.6730204348417526\n",
      "1.2871816693023543\n",
      "0.8690744814291882\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.2\n",
      "0.6710600676981706\n",
      "1.263603779185492\n",
      "0.8738269962529358\n",
      "\n",
      "\n",
      "n_estimators: 1000\n",
      "learning_rate: 0.5\n",
      "0.7306328730575568\n",
      "1.3218368702180292\n",
      "0.8619296794572661\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.05\n",
      "0.6722637992921247\n",
      "1.231560938776842\n",
      "0.8801449266568235\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.1\n",
      "0.6631477753075266\n",
      "1.2723469958312414\n",
      "0.8720749052115069\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.2\n",
      "0.6692857452353961\n",
      "1.25738317047685\n",
      "0.8750662153328289\n",
      "\n",
      "\n",
      "n_estimators: 1500\n",
      "learning_rate: 0.5\n",
      "0.7304027596517187\n",
      "1.3217139762434038\n",
      "0.8619553516443197\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.05\n",
      "0.6607046282925357\n",
      "1.2156648941826442\n",
      "0.8832189540332084\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.1\n",
      "0.6586651983297651\n",
      "1.2615880532892556\n",
      "0.8742292225503778\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.2\n",
      "0.6678674732954061\n",
      "1.256318167580999\n",
      "0.8752777634064656\n",
      "\n",
      "\n",
      "n_estimators: 2000\n",
      "learning_rate: 0.5\n",
      "0.7303570298607063\n",
      "1.321694513674356\n",
      "0.8619594170983702\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        model = XGBRegressor(n_estimators = n_estimators,learning_rate = learning_rate,random_state= 0,nthread = 20)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        print('n_estimators: '+ str(n_estimators))\n",
    "        print('learning_rate: '+ str(learning_rate))\n",
    "        print(mean_absolute_error(y_val, y_pred))\n",
    "        print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "        print(r2_score(y_val, y_pred))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = [0.9,0.8,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.9\n",
      "0.6556697081936567\n",
      "1.2261928608421584\n",
      "0.88118748843388\n",
      "\n",
      "\n",
      "subsample: 0.8\n",
      "0.6453874792335211\n",
      "1.2378336564595855\n",
      "0.8789209000876078\n",
      "\n",
      "\n",
      "subsample: 0.5\n",
      "0.6528309253114698\n",
      "1.2177260727335704\n",
      "0.8828226101902347\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subsample in subsample_list:\n",
    "    model = XGBRegressor(subsample = subsample, n_estimators = 2000,learning_rate = 0.1,random_state= 0,nthread = 24)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('subsample: '+ str(subsample))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_list = [0.9,0.8,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.9\n",
      "0.6711867144810703\n",
      "1.2914498561657375\n",
      "0.8682047657037091\n",
      "\n",
      "\n",
      "subsample: 0.8\n",
      "0.6762502741046338\n",
      "1.2466214971698453\n",
      "0.8771956266020196\n",
      "\n",
      "\n",
      "subsample: 0.5\n",
      "0.7162711563863214\n",
      "1.305029506447866\n",
      "0.8654185286037612\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subsample in subsample_list:\n",
    "    model = XGBRegressor(subsample = subsample, n_estimators = 2000,learning_rate = 0.2,random_state= 0,nthread = 24)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('subsample: '+ str(subsample))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定为2000，0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/basic_train_0.70_FP.csv',header = None)\n",
    "df_val = pd.read_csv('./Dataset/basic_val_0.15_FP.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5905, 9122)\n",
      "(1265, 9122)\n"
     ]
    }
   ],
   "source": [
    "train_data_label = np.array(df_train)\n",
    "print(train_data_label.shape)\n",
    "val_data_label = np.array(df_val)\n",
    "print(val_data_label.shape)\n",
    "X_train, X_val, y_train, y_val = train_data_label[:,1:],val_data_label[:,1:],train_data_label[:,0],val_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deep_list = [5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax_deep: 5\n",
      "0.6213195248185172\n",
      "0.9982754455123014\n",
      "0.8992652909451064\n",
      "\n",
      "\n",
      "smax_deep: 7\n",
      "0.6073614288743351\n",
      "0.976829382491392\n",
      "0.903546989486959\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_depth  in max_deep_list:\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = max_depth ,subsample = 0.8,nthread = 16,seed = 0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('smax_deep: '+ str(max_depth))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618175430672901\n",
      "1.0099875035942194\n",
      "0.896887727297148\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smax_deep: 3\n",
    "0.7031126156549887\n",
    "1.0559855457666045\n",
    "0.8872817322702732\n",
    "\n",
    "smax_deep: 9\n",
    "0.618175430672901\n",
    "1.0099875035942194\n",
    "0.896887727297148\n",
    "\n",
    "smax_deep: 4\n",
    "0.6481165445173948\n",
    "1.013272175094667\n",
    "0.8962159552517509\n",
    "\n",
    "\n",
    "smax_deep: 6\n",
    "0.615080996165443\n",
    "0.996544908876053\n",
    "0.8996142407400285\n",
    "\n",
    "\n",
    "smax_deep: 8\n",
    "0.6038909023760963\n",
    "0.9782681460715427\n",
    "0.9032626506248257\n",
    "\n",
    "smax_deep: 5\n",
    "0.6213195248185172\n",
    "0.9982754455123014\n",
    "0.8992652909451064\n",
    "\n",
    "\n",
    "smax_deep: 7\n",
    "0.6073614288743351\n",
    "0.976829382491392\n",
    "0.903546989486959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acidic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/acidic_train_0.70_FP.csv',header = None)\n",
    "df_val = pd.read_csv('./Dataset/acidic_val_0.15_FP.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6337, 9122)\n",
      "(1358, 9122)\n"
     ]
    }
   ],
   "source": [
    "train_data_label = np.array(df_train)\n",
    "print(train_data_label.shape)\n",
    "val_data_label = np.array(df_val)\n",
    "print(val_data_label.shape)\n",
    "X_train, X_val, y_train, y_val = train_data_label[:,1:],val_data_label[:,1:],train_data_label[:,0],val_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deep_list = [3,4,6,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax_deep: 3\n",
      "0.7392428957170537\n",
      "1.388929973838191\n",
      "0.8475577638886678\n",
      "\n",
      "\n",
      "smax_deep: 4\n",
      "0.6834616828284145\n",
      "1.3434431504865485\n",
      "0.857379092066732\n",
      "\n",
      "\n",
      "smax_deep: 6\n",
      "0.6453874792335211\n",
      "1.2378336564595855\n",
      "0.8789209000876078\n",
      "\n",
      "\n",
      "smax_deep: 9\n",
      "0.62579508360513\n",
      "1.1709544211178575\n",
      "0.8916510788411793\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for max_depth  in max_deep_list:\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = max_depth ,subsample = 0.8,nthread = 16,seed = 0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print('smax_deep: '+ str(max_depth))\n",
    "    print(mean_absolute_error(y_val, y_pred))\n",
    "    print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "    print(r2_score(y_val, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax_deep: 9\n",
      "0.6166865079096367\n",
      "1.1195080092642171\n",
      "0.9009626479901784\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 10 ,subsample = 0.8,nthread = 36,seed = 0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print('smax_deep: '+ str(max_depth))\n",
    "print(mean_absolute_error(y_val, y_pred))\n",
    "print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "print(r2_score(y_val, y_pred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6292941898622021\n",
      "1.0998602681839982\n",
      "0.8999321891781235\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [50,100,300,500,1000,1500,2000,3000]\n",
    "learning_rate_list = [0.05,0.1,0.2,0.5]\n",
    "subsample_list = [1,0.9,0.8,0.5]\n",
    "max_deep_list = [4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9172fadf77c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmax_deep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_deep_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnthread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators:'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xjc/anaconda/envs/rdkit-env/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    546\u001b[0m                               \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xjc/anaconda/envs/rdkit-env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xjc/anaconda/envs/rdkit-env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xjc/anaconda/envs/rdkit-env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for subsample in subsample_list:\n",
    "            for max_deep in max_deep_list:\n",
    "                model = XGBRegressor(subsample = subsample, n_estimators = 2000,learning_rate = 0.2,random_state= 0,nthread = 36)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "                print('n_estimators:'+ str(n_estimators))\n",
    "                print('learning_rate: '+ str(learning_rate))\n",
    "                print('subsample: '+ str(subsample))\n",
    "                print('max_deep: '+ str(max_deep))\n",
    "                print(mean_absolute_error(y_val, y_pred))\n",
    "                print(mean_squared_error(y_val, y_pred)**0.5)\n",
    "                print(r2_score(y_val, y_pred))\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
