{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/basic_train_0.70_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=2000, n_jobs=30, nthread=30, num_parallel_tree=1,\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 24)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234349939252035\n",
      "1.01881500007192\n",
      "0.8874069007273923\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.615080996165443\n",
      "0.996544908876053\n",
      "0.8996142407400285\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./Dataset/basic_val_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/acidic_train_0.70_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=2000, n_jobs=24, nthread=24, num_parallel_tree=1,\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 24)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6358491836038331\n",
      "1.1058553291916215\n",
      "0.8988383272859848\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6453874792335211\n",
      "1.2378336564595855\n",
      "0.8789209000876078\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('./Dataset/acidic_val_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/basic_train_0.70_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./Dataset/basic_test_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884205565603349\n",
      "0.6320396966763908\n",
      "1.0331973567541826\n",
      "0.8844834196086927\n",
      "0.6311499665421315\n",
      "1.0319570102448734\n",
      "0.8827973117366738\n",
      "0.6325447643858002\n",
      "1.0394610733885348\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 16,seed = i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "    file = open(\"./Machine_learning_model/basic_XGBoost_{}.pickle\".format(i), \"wb+\")\n",
    "    pickle.dump(model, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acidic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/acidic_train_0.70_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./Dataset/acidic_test_0.15_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8985925226106974\n",
      "0.6365571816432178\n",
      "1.1071980288624135\n",
      "0.8949930632252283\n",
      "0.6578560298301941\n",
      "1.1266766895782805\n",
      "0.9061319469509963\n",
      "0.646156457563291\n",
      "1.0652443007346302\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 16,seed = i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "    file = open(\"./Machine_learning_model/acidic_XGBoost_{}.pickle\".format(i), \"wb+\")\n",
    "    pickle.dump(model, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已经跑过了，点错了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/basic_cluster_0.3_train_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./Dataset/basic_cluster_0.3_test_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517290512838971\n",
      "0.7624395101994362\n",
      "1.1679415102530866\n",
      "0.8499008698110575\n",
      "0.7723122961309405\n",
      "1.1751198129862421\n",
      "0.8482323831387415\n",
      "0.7720286588229907\n",
      "1.181633019163779\n",
      "0.8479960061248091\n",
      "0.7753608911559576\n",
      "1.1825528537728551\n",
      "0.8542822770601608\n",
      "0.7614558267240555\n",
      "1.1578418659190928\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 16,seed = i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "    file = open(\"./Machine_learning_model/basic_cluster_XGBoost_{}.pickle\".format(i), \"wb+\")\n",
    "    pickle.dump(model, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acidic cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Dataset/acidic_cluster_0.3_train_FP.csv',header = None)\n",
    "train_data_label = np.array(df_train)\n",
    "X_train, y_train = train_data_label[:,1:],train_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./Dataset/acidic_cluster_0.3_test_FP.csv',header = None)\n",
    "test_data_label = np.array(df_test)\n",
    "X_test, y_test = test_data_label[:,1:],test_data_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887064133748408\n",
      "0.7265403157548719\n",
      "1.195060275056094\n",
      "0.8776413960380876\n",
      "0.7213590881091027\n",
      "1.2439161982728022\n",
      "0.8834546596475292\n",
      "0.7098421659739587\n",
      "1.2140073715965825\n",
      "0.8719301170114355\n",
      "0.7349121446809205\n",
      "1.2726159819417748\n",
      "0.8830785304318063\n",
      "0.7332825153428063\n",
      "1.2159647892622212\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    model = XGBRegressor(n_estimators = 2000,learning_rate = 0.1,max_depth = 6,subsample = 0.8,nthread = 16,seed = i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print(mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "    file = open(\"./Machine_learning_model/acidic_cluster_XGBoost_{}.pickle\".format(i), \"wb+\")\n",
    "    pickle.dump(model, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
